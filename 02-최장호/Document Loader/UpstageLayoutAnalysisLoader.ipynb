{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-upstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPSTAGE_API_KEY=\"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- file_path: 분석할 문서 경로\n",
    "- output_type: 출력 형식 [(기본값)'html', 'text']\n",
    "- split: 문서 분할 방식 ['none', 'element', 'page']\n",
    "- use_ocr=True: OCR 사용\n",
    "- exclude=[\"header\", \"footer\"]: 헤더, 푸터 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Deep Generative Models: Survey' metadata={'page': 1, 'id': 0, 'bounding_box': '[{\"x\": 294, \"y\": 108}, {\"x\": 980, \"y\": 108}, {\"x\": 980, \"y\": 163}, {\"x\": 294, \"y\": 163}]', 'category': 'heading1'}\n",
      "page_content='Achraf Oussidi\n",
      "Master, Data Science and Big Data\n",
      "ENSIAS\n",
      "Mohammed V University, Rabat, Morocco\n",
      "Email: achraf.oussidi@gmail.com' metadata={'page': 1, 'id': 1, 'bounding_box': '[{\"x\": 209, \"y\": 193}, {\"x\": 584, \"y\": 193}, {\"x\": 584, \"y\": 322}, {\"x\": 209, \"y\": 322}]', 'category': 'paragraph'}\n",
      "page_content='Abstract-Generative models have found their way to the\n",
      "forefront of deep learning the last decade and so far, it seems\n",
      "that the hype will not fade away any time soon. In this paper,\n",
      "we give an overview of the most important building blocks of\n",
      "most recent revolutionary deep generative models such as RBM,\n",
      "DBM, DBN, VAE and GAN. We will also take a look at three\n",
      "of state-of-the-art generative models, namely PixelRNN, DRAW\n",
      "and NADE. We will delve into their unique architectures, the\n",
      "learning procedures and their potential and limitations. We will\n",
      "also review some of the known issues that arise when trying to\n",
      "design and train deep generative architectures using shallow ones\n",
      "and how different models deal with these issues. This paper is not\n",
      "meant to be a comprehensive study of these models, but rather\n",
      "a starting point for those who bear an interest in the field.' metadata={'page': 1, 'id': 2, 'bounding_box': '[{\"x\": 96, \"y\": 403}, {\"x\": 629, \"y\": 403}, {\"x\": 629, \"y\": 698}, {\"x\": 96, \"y\": 698}]', 'category': 'paragraph'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "\n",
    "# 파일 경로\n",
    "file_path = \"C:/Users/kowm6/Desktop/Deep Generative Models Survey.pdf\"\n",
    "\n",
    "# 문서 로더 설정\n",
    "loader = UpstageLayoutAnalysisLoader(\n",
    "    file_path,\n",
    "    output_type=\"text\",\n",
    "    split=\"element\",\n",
    "    use_ocr=True,\n",
    "    exclude=[\"header\", \"footer\"],\n",
    "    api_key=UPSTAGE_API_KEY\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 결과 출력\n",
    "for doc in docs[:3]:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 3}, page_content='the adjacent layers. Similar to RBMs, there are no connections\\nbetween units of the same layer (fig. 3). DBMs can also be\\nviewed as a group of RBMs stacked together (fig. 4). h h\\n1,1 3.1\\n1 2 h\\n2,3\\nh h\\n1.2 3.2\\nVi h\\n2,2\\nh h\\n1.3 3.3\\nV3 h\\n2.1\\nh h\\n1,4 3.4 is trained independently, and a fine tuning (slow) stage where\\nthe network as a whole is trained using a variation of the\\nwake-sleep algorithm [22]. h h\\n1.1 3.1\\nV2 h\\n2,3\\nh h.\\n1,2 3,2\\nV h\\n2,2\\nh h\\n1,3 3,3\\nV3 h\\n2,1\\nh h.\\n1,4 3,4 Fig. 3. A Deep Boltzmann Machine with 1 visible layer (in blue) and 3\\nhidden layers (in red). Fig. 5. A Deep Belief Network with a similar architecture to The DBM in\\nfig. 3. In DBNs, all connections are undirected except for the top two layers. bve\\nDas\\n41 1\\nW\\n5 W\\nb⌀\\n1.2 bys\\n▶>\\nV2 D22\\nい\\n心\\nby2\\nマン\\n수 冬 2\\nh. h. h\\n1 1 ,4 3.1 Fig. 4. The same DBM from fig. 3 decomposed into 3 RBMs. Every two\\nconsecutive layers, when taken together, will form an RBM. Training of DBMs is often done in two stages: a pre-\\ntraining stage where every RBM is trained independently and\\na fine tuning stage where the network is trained at once using\\nbackpropagation. [19] 4) Deep Belief Networks: Deep belief networks are another\\ndeep architectures consisting of many hidden layers that\\nrevolutionized the deep learning scene when they were first\\nintroduced in 2006. [20]. Similar to DBMs, DBNs do not have\\nconnections within the same layer. The difference between the\\ntwo is that in DBN only the top two layers have directed\\nconnections pointing towards the visible layer, the rest all\\nhave undirected connections (fig. 5). The most widely used\\nmethod to train a DBN is a greedy layer-wise fast algorithm\\nintroduced by Hinton et al. [21]. Similar to the algorithm\\ndescribed above for training DBMs, this algorithm consists\\nof two stages: an initialization (fast) stage where every layer Sampling from a DBN is done by first running multiple\\nsteps of Gibbs sampling on the two hidden layers with directed\\nconnections. We then use the sampled latent variables to draw\\nsamples from the visible units by running a step of ancestral\\nsampling through the network. B. Autoencoders An autoencoder is a neural network trained for the purpose\\nof recreating its input as the output. It is a feedforward non-\\nrecurrent network of which the aim is to continually reduce\\nthe dimensionality to a smaller hidden layer often called the\\ncode representative of the input. In a similar but mirroring\\nprocess, the network then recreates the same input structure\\nfrom the code layer. The first part is called the encoder and\\nthe second decoder (fig. 6). The goal of an autoencoder is not to perfectly copy the input\\nto the output. Therefore, we must prevent it from learning a\\ntrivial identity function which comes easily if the autoencoder\\nis not properly \"restrained\". The aim is for our model to\\npick up the underlying patterns and characteristics of the data\\ndistribution to be able to generate new never seen before\\nexamples of the same distribution as the examples provided\\nduring the training phase. Formally, an autoencoder can be\\nwritten in a deterministic way (although, it is not usually the\\ncase) as a composition of two functions: x = fa(h) where h = fe(x) Where fe is the encoder, fa is the decoder, x is the input\\nvariable and h is the code.\\nSince an autoencoder is a particular case of neural networks,\\nit can be trained using the standard techniques for training\\nfeedforward neural networks, such as mini batch gradient\\ndescent and back-propagation.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (app)",
   "language": "python",
   "name": "app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
