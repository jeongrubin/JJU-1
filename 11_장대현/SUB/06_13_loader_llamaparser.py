# -*- coding: utf-8 -*-
"""06_13_Loader_LLaMAParser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wSkOCFwRiwuzPwIArIBWW2TB6rUSnt5z

# UPSTAGE
"""

!pip install -qU langchain-upstage

from langchain_upstage import UpstageLayoutAnalysisLoader

api_key = "Your API Key"

# 파일 경로
file_path = "/content/attention_paper.pdf"

# 문서 로더 설정
loader = UpstageLayoutAnalysisLoader(
    file_path,
    output_type="text",
    split="page",
    use_ocr=True,
    exclude=["header", "footer"],
    api_key=api_key
)

# 문서 로드
docs = loader.load()

docs[0].page_content

"""# LLaMA Parser"""

!pip install -qU llama-index-core llama-parse llama-index-readers-file python-dotenv

import os
import nest_asyncio

LLAMA_CLOUD_API_KEY = 'Your API Key'
nest_asyncio.apply()

"""# Basic Parser"""

from llama_parse import LlamaParse
from llama_index.core import SimpleDirectoryReader

# 파서 설정
parser = LlamaParse(
    result_type="markdown",  # "markdown"과 "text" 사용 가능
    num_workers=8,  # worker 수 (기본값: 4)
    verbose=True,
    language="en",
    api_key=LLAMA_CLOUD_API_KEY
)

# SimpleDirectoryReader를 사용하여 파일 파싱
file_extractor = {".pdf": parser}

# LlamaParse로 파일 파싱
documents = SimpleDirectoryReader(
    input_files=["/content/attention_paper.pdf"],
    file_extractor=file_extractor,
).load_data()

len(documents)

print(documents[0])

"""# LLaMAIndex -> LangChain Document 로 변환"""

!pip install -qU langchain_community

# 랭체인 Document 변환
docs = [doc.to_langchain_format() for doc in documents]

print(docs[6].page_content)

# metadata 출력
docs[0].metadata

"""MultiModal Model 로 파싱
주요 파라미터

- `use_vendor_multimodal_model`: 멀티모달 모델 사용 여부를 지정합니다. True로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.

- `vendor_multimodal_model_name`: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 "openai-gpt4o"를 사용하고 있습니다.

- `vendor_multimodal_api_key`: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.

- `result_type`: 파싱 결과의 형식을 지정합니다. "markdown"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.

- `language`: 파싱할 문서의 언어를 지정합니다. "ko"로 설정되어 한국어로 처리됩니다.

- `skip_diagonal_text`: 대각선 텍스트를 건너뛸지 여부를 결정합니다.

- `page_separator`: 페이지 구분자를 지정할 수 있습니다.
"""

documents = LlamaParse(
    use_vendor_multimodal_model=True,
    vendor_multimodal_model_name="openai-gpt4o",
    vendor_multimodal_api_key=os.environ["OPENAI_API_KEY"],
    result_type="markdown",
    language="ko",
    # skip_diagonal_text=True,
    # page_separator="\n=================\n"
)

OPENAI_API_KEY = "Your API Key"

documents = LlamaParse(
    use_vendor_multimodal_model=True,
    vendor_multimodal_model_name="openai-gpt4o",
    vendor_multimodal_api_key=OPENAI_API_KEY,
    api_key = LLAMA_CLOUD_API_KEY,
    result_type="markdown",
    language="en",
    # skip_diagonal_text=True,
    # page_separator="\n=================\n"
)

# parsing 된 결과
parsed_docs = documents.load_data(file_path="/content/attention_paper.pdf")

# langchain document 변환
docs = [doc.to_langchain_format() for doc in parsed_docs]

print(docs[5].page_content)

"""# 사용자 정의 인스트럭션 지정

"""

# parsing instruction 을 지정합니다.
parsing_instruction = (
    "You are parsing a brief of AI Report. Please extract tables in markdown format."
)

# LlamaParse 설정
parser = LlamaParse(
    use_vendor_multimodal_model=True,
    vendor_multimodal_model_name="openai-gpt4o",
    vendor_multimodal_api_key=OPENAI_API_KEY,
    result_type="markdown",
    language="en",
    parsing_instruction=parsing_instruction,
    api_key = LLAMA_CLOUD_API_KEY
)

# parsing 된 결과
parsed_docs = parser.load_data(file_path="/content/attention_paper.pdf")

# langchain 도큐먼트로 변환
docs = [doc.to_langchain_format() for doc in parsed_docs]

print(docs[1].page_content)