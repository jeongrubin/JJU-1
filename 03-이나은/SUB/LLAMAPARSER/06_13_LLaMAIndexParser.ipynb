{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -qU llama-index-core llama-parse llama-index-reders-file python-dotenv"
      ],
      "metadata": {
        "id": "QgV7af-S-1rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0gXGaJe9T4y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "LLAMA_CLOUD_API_KEY = ''\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ba"
      ],
      "metadata": {
        "id": "ggK8THf5_I41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU llama_parse llama_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpq5TgBbADjG",
        "outputId": "a878b469-ee5b-422a-d7bb-eff9860084cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/242.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU llama-index-core llama-parse llama-index-readers-file python-dotenv"
      ],
      "metadata": {
        "id": "303kP-bDCEqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# 파서 설정\n",
        "parser = LlamaParse(\n",
        "    result_type=\"markdown\",  # \"markdown\"과 \"text\" 사용 가능\n",
        "    num_workers=8,  # worker 수 (기본값: 4)\n",
        "    verbose=True,\n",
        "    language=\"ko\",\n",
        "    api_key = LLAMA_CLOUD_API_KEY\n",
        ")\n",
        "\n",
        "# SimpleDirectoryReader를 사용하여 파일 파싱\n",
        "file_extractor = {\".pdf\": parser}\n",
        "\n",
        "# LlamaParse로 파일 파싱\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"/content/SPRI_AI_Brief_2023년12월호_F.pdf\"],\n",
        "    file_extractor=file_extractor,\n",
        ").load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RN20VSW-p8l",
        "outputId": "fdf5c6b5-34c8-48d5-fd40-5707f381bf68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id e6269809-0069-43de-909b-19d67806bce3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXGAVc16AfTK",
        "outputId": "3f7fd7a9-2288-48f3-9da7-c7d0862574c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id_='313a725e-f56d-4e28-9c44-0f6298b8c169', embedding=None, metadata={'file_path': '/content/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_type': 'application/pdf', 'file_size': 975735, 'creation_date': '2025-01-07', 'last_modified_date': '2025-01-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# 인공지능 산업의 최신 동향\\n\\n2023년 12월호', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LlamaIndex > LangChain Document 변환"
      ],
      "metadata": {
        "id": "fqrbWIqzCtmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Oex-B9iC-d0",
        "outputId": "72299506-e09b-49dd-d768-56f5a01b5e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/2.5 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 랭체인 도큐멘터로 변환\n",
        "docs = [doc.to_langchain_format() for doc in documents]"
      ],
      "metadata": {
        "id": "E5VEuoT7Cbmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ywzo3k_0DGpI",
        "outputId": "79ee3153-9686-4acc-e066-f2ff2bfaccb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# 인공지능 산업의 최신 동향\\n\\n2023년 12월호'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[5].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "DkvDDOcfDZkF",
        "outputId": "8b83c1c4-37e9-45b9-fe69-af257c01a1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# 정책/법제\\n\\n# 기업/산업\\n\\n# 연구기술\\n\\n# 인력/교육\\n\\n# 영국AI안전성정상회의에참가한28개국,AI위험에공동대응선언\\n\\n영국블레츨리파크에서개최된AI안전성정상회의에참가한28개국들이AI안전보장을위한협력방안을담은블레츨리선언을발표\\n\\n첨단AI를개발하는국가와기업들은AI시스템에대한안전테스트계획에합의했으며,\\n\\n영국의AI안전연구소가전세계국가와협력해테스트를주도할예정\\n\\n# AI안전성정상회의참가국들,블레츨리선언통해AI안전보장을위한협력에합의\\n\\n2023년11월1~2일영국블레츨리파크에서열린AI안전성정상회의(AISafetySummit)에참가한28개국대표들이AI위험관리를위한‘블레츨리선언’을발표\\n\\n- 선언은AI안전보장을위해국가,국제기구,기업,시민사회,학계를포함한모든이해관계자의협력이중요하다고강조했으며,특히최첨단AI시스템개발기업은안전평가를비롯한적절한조치를취하여AI시스템의안전을보장할책임이있다고지적\\n- 각국은AI안전보장을위해첨단AI개발기업의투명성향상,적절한평가지표와안전테스트도구개발,공공부문역량구축과과학연구개발등의분야에서협력하기로합의\\n\\n# 영국총리,정부주도의첨단AI시스템안전테스트계획발표\\n\\n리시수낙영국총리는AI안전성정상회의를마무리하며첨단AI모델에대한안전성시험계획수립과테스트수행을주도할영국AI안전연구소의출범을발표\\n\\n- 첨단AI모델의안전테스트는국가안보와안전,사회적피해를포함한여러잠재적유해기능에대한시험을포함하며,참석자들은정부주도의외부안전테스트에합의\\n- 각국정부는테스트와기타안전연구를위한공공부문역량에투자하고,테스트결과가다른국가와관련된경우해당국가와결과를공유하며,적절한시기에공동표준개발을위해노력하기로합의\\n\\n참가국들은튜링상을수상한AI학자인요슈아벤지오교수가주도하는‘과학의현황(Stateof the Science)’보고서작성에도합의했으며,보고서를통해첨단AI의위험과가능성에관한기존연구를과학적으로평가하고향후AI안전연구를위한우선순위를제시할계획\\n\\n한국은영국정부와6개월뒤에온라인으로AI미니정상회의를공동개최하기로합의했으며,프랑스정부와는1년후대면정상회의를개최할예정\\n\\n출처: Gov.uk, TheBletchley Declaration by Countries Attending the AISafety Summit, 1-2 November 2023, 2023.11.01.\\n\\nGov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global Safety AI Summit concludes, 2023.11.02.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We-SjqLZDlws",
        "outputId": "56015417-a3b5-4125-ee75-b5b97df137cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'file_path': '/content/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
              " 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
              " 'file_type': 'application/pdf',\n",
              " 'file_size': 975735,\n",
              " 'creation_date': '2025-01-07',\n",
              " 'last_modified_date': '2025-01-07'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MultiModal Model 로 파싱\n",
        "\n",
        "\n",
        "주요 파라미터\n",
        "\n",
        "* use_vendor_multimodal_model: 멀티모달 모델 사용 여부를 지정합니다. True로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.\n",
        "*  vendor_multimodal_model_name: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 \"openai-gpt4o\"를 사용하고 있습니다.\n",
        "*   vendor_multimodal_api_key: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.\n",
        "*   result_type: 파싱 결과의 형식을 지정합니다. \"markdown\"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.\n",
        "*   language: 파싱할 문서의 언어를 지정합니다. \"ko\"로 설정되어 한국어로 처리됩니다\n",
        "*   skip_diagonal_text: 대각선 텍스트를 건너뛸지 여부를 결정합니다.\n",
        "* page_separator: 페이지 구분자를 지정할 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XW2gZ7cqEsw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"\"\n",
        "\n",
        "documents = LlamaParse(\n",
        "    use_vendor_multimodal_model = True,\n",
        "    vendor_multimodal_model_name = 'openai-gpt-4o',\n",
        "    vendor_multimoal_api_key = OPENAI_API_KEY,\n",
        "    api_key = LLAMA_CLOUD_API_KEY,\n",
        "    result_type = 'markdown',\n",
        "    language = 'ko',\n",
        "    skip_diagonal_text = True,\n",
        ")"
      ],
      "metadata": {
        "id": "vCg4a_tzEZPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_docs = documents.load_data(file_path = '/content/SPRI_AI_Brief_2023년12월호_F.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHzpdlfuFmZN",
        "outputId": "705fe7f1-28de-4bfc-dc75-def8b4f54c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error while parsing the file '/content/SPRI_AI_Brief_2023년12월호_F.pdf': Failed to parse the file: {\"detail\":\"Vendor multimodal model openai-gpt-4o is not supported. Supported models are ['openai-gpt4o', 'anthropic-sonnet-3.5', 'openai-gpt-4o-mini', 'gemini-1.5-flash', 'gemini-1.5-pro', 'custom-azure-model']\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [doc.to_langchain_format() for doc in parsed_docs]"
      ],
      "metadata": {
        "id": "XxKqkz05Ha3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing Instruction"
      ],
      "metadata": {
        "id": "3Uys9x9GL74k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsing_instruction = (\n",
        "    \"hi\"\n",
        ")\n",
        "\n",
        "parser = LlamaParse(\n",
        "    use_vendor_multimodal_model=True,  # 오타 수정: use_vendor_muitimoal_model -> use_vendor_multimodal_model\n",
        "    vendor_multimodal_model_name='openai-gpt4o',\n",
        "    vendor_multimodal_api_key='',\n",
        "    result_type='markdown',\n",
        "    language='ko',\n",
        "    skip_diagonal_text=True,\n",
        "    parsing_instruction=parsing_instruction,\n",
        "    api_key=LLAMA_CLOUD_API_KEY  # API 키 추가\n",
        ")\n",
        "\n",
        "parser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xczneuadH1-U",
        "outputId": "c0111fcd-6162-4753-bb7a-c68b31dca6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaParse(is_remote=False, api_key='llx-qn8jeUc5OyS1AcvliALPBKmFImgpcXh1k2iv6u7ha741KP7q', base_url='https://api.cloud.llamaindex.ai', check_interval=1, custom_client=None, ignore_errors=True, max_timeout=2000, num_workers=4, result_type=<ResultType.MD: 'markdown'>, show_progress=True, split_by_page=True, verbose=True, annotate_links=False, auto_mode=False, auto_mode_trigger_on_image_in_page=False, auto_mode_trigger_on_table_in_page=False, auto_mode_trigger_on_text_in_page=None, auto_mode_trigger_on_regexp_in_page=None, azure_openai_api_version=None, azure_openai_deployment_name=None, azure_openai_endpoint=None, azure_openai_key=None, bbox_bottom=None, bbox_left=None, bbox_right=None, bbox_top=None, continuous_mode=False, disable_ocr=False, disable_image_extraction=False, do_not_cache=False, do_not_unroll_columns=False, extract_charts=False, extract_layout=False, fast_mode=False, guess_xlsx_sheet_names=False, html_make_all_elements_visible=False, html_remove_fixed_elements=False, html_remove_navigation_elements=False, http_proxy=None, invalidate_cache=False, is_formatting_instruction=False, language='ko', max_pages=None, output_pdf_of_document=False, output_s3_path_prefix=None, page_prefix=None, page_separator=None, page_suffix=None, parsing_instruction='hi', premium_mode=False, skip_diagonal_text=True, structured_output=False, structured_output_json_schema=None, structured_output_json_schema_name=None, take_screenshot=False, target_pages=None, use_vendor_multimodal_model=True, vendor_multimodal_api_key='', vendor_multimodal_model_name='openai-gpt4o', webhook_url=None, bounding_box=None, gpt4o_mode=False, gpt4o_api_key=None)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWdVKot9M-TI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}