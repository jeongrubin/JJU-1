{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 10516,
     "status": "ok",
     "timestamp": 1736150084913,
     "user": {
      "displayName": "유상민",
      "userId": "13412534722180768201"
     },
     "user_tz": -540
    },
    "id": "VvnTLGi6m3DB",
    "outputId": "6323df4c-a555-4c0d-fec3-114c1502fee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_upstage\n",
      "  Downloading langchain_upstage-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_upstage) (0.3.25)\n",
      "Collecting langchain-openai<0.3,>=0.2 (from langchain_upstage)\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pypdf<5.0.0,>=4.2.0 (from langchain_upstage)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from langchain_upstage) (2.32.3)\n",
      "Collecting tokenizers<0.20.0,>=0.19.1 (from langchain_upstage)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_upstage) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_upstage) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_upstage) (0.2.3)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_upstage) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_upstage) (2.10.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_upstage) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_upstage) (4.12.2)\n",
      "Collecting langchain-core<0.4,>=0.3.0 (from langchain_upstage)\n",
      "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai<0.3,>=0.2->langchain_upstage)\n",
      "  Downloading openai-1.59.3-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai<0.3,>=0.2->langchain_upstage)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (2024.12.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.20.0,>=0.19.1->langchain_upstage) (0.27.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain_upstage) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain_upstage) (2024.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain_upstage) (4.67.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_upstage) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_upstage) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_upstage) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_upstage) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain_upstage) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain_upstage) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain_upstage) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain_upstage) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_upstage) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_upstage) (2.27.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai<0.3,>=0.2->langchain_upstage) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain_upstage) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_upstage) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_upstage) (0.14.0)\n",
      "Downloading langchain_upstage-0.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.59.3-py3-none-any.whl (454 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf, tiktoken, tokenizers, openai, langchain-core, langchain-openai, langchain_upstage\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.57.4\n",
      "    Uninstalling openai-1.57.4:\n",
      "      Successfully uninstalled openai-1.57.4\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.25\n",
      "    Uninstalling langchain-core-0.3.25:\n",
      "      Successfully uninstalled langchain-core-0.3.25\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.29 langchain-openai-0.2.14 langchain_upstage-0.4.0 openai-1.59.3 pypdf-4.3.1 tiktoken-0.8.0 tokenizers-0.19.1\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain_upstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1736150090398,
     "user": {
      "displayName": "유상민",
      "userId": "13412534722180768201"
     },
     "user_tz": -540
    },
    "id": "I3aJW8Rxmx-T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22091,
     "status": "ok",
     "timestamp": 1736150171161,
     "user": {
      "displayName": "유상민",
      "userId": "13412534722180768201"
     },
     "user_tz": -540
    },
    "id": "WO5SuOU_m6LD",
    "outputId": "b673a49b-137a-4057-bb2a-0dfba43574d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m506.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laD7rpYonOYt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96428,
     "status": "ok",
     "timestamp": 1736151814340,
     "user": {
      "displayName": "유상민",
      "userId": "13412534722180768201"
     },
     "user_tz": -540
    },
    "id": "3QxZuEf1n1o8",
    "outputId": "77a4fc8e-ce95-4ac1-98d7-307b665b7441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='<h1 id='26' style='font-size:20px'>I. 서론</h1> <h1 id='27' style='font-size:16px'>1.1 연구 배경</h1> <br><p id='28' data-category='paragraph' style='font-size:16px'>육계 농장에서의 닭 중량 추정은 현대 축산업에서 점점 더 중요한 과제로 대두되고 있<br>다. 이는 농가의 생산성과 직결될 뿐만 아니라, 경제적 이익을 극대화하는 데 있어서도<br>핵심적인 역할을 한다. 특히, 육계 계열사와 농가 간의 계약은 정량적이고 명확한 중량<br>기준을 포함하고 있으며, 이를 충족하지 못할 경우 농가는 불이익을 감수해야 한다. 예를<br>들어, 계약서에 명시된 ±50g의 목표 중량 범위를 초과하거나 충족하지 못할 경우, 농가<br>는 페널티를 받게 되는 반면, 이를 준수하면 인센티브를 받을 수 있다. 이러한 계약 구조<br>는 농가가 닭의 중량을 정확히 관리할 필요성을 더욱 부각시킨다.</p> <br><p id='29' data-category='paragraph' style='font-size:16px'>하지만 전통적인 방식의 중량 관리에는 여러 가지 한계가 존재한다. 우선, 하루에 수백<br>마리의 닭의 무게를 개별적으로 측정해야 하는데, 이 과정에서 많은 인력과 시간이 소요<br>된다. 이는 노동 비용 증가로 이어질 뿐만 아니라, 잦은 핸들링으로 인해 닭에게 스트레<br>스를 유발할 수 있다. 스트레스는 닭의 성장 속도를 저하시킬 뿐만 아니라, 품질에도 부<br>정적인 영향을 미친다. 또한, 최근 몇 년간 조류 인플루엔자와 같은 질병의 확산 위험이<br>증가하면서 닭을 빈번하게 접촉하는 행위가 전염 확산의 주요 원인 중 하나로 지목되고<br>있다.</p> <br><p id='30' data-category='paragraph' style='font-size:16px'>이에 따라, 정확하고 효율적인 닭 중량 추정 모델과 이를 활용한 시스템의 개발이 필<br>수적이다. 중량 추정 기술이 고도화되면 농가의 손실을 최소화하고, 닭의 스트레스를 줄<br>이며, 더 나아가 질병 확산의 위험을 감소시킬 수 있다. 또한, 출하 시기를 최적화함으로<br>써 육계 계열사와 농가 간의 계약 조건을 충족시키고, 생산성과 수익성을 높이는 데 기<br>여할 수 있다.</p>' metadata={'page': 10}\n",
      "page_content='<caption id='0' style='font-size:18px'><표 1> 농장과 계열사 회사의 연평균 사육 손실금액</caption> <table id='1' style='font-size:16px'><tr><td colspan=\"2\">구분</td><td>산출내용</td><td>손실 금액 (억원)</td></tr><tr><td rowspan=\"3\">육 계</td><td>농장</td><td>사료요구율(0.02) x 사료단가(500원/kg) x 전국농장(1643호) x 평균사육두수(7만수) x 평체(1.6kg) x 평균회전수(6회) x FCR(1.5) = 165.6억원/연간</td><td>165.6</td></tr><tr><td>계열화회사사 육손실</td><td>도계총수(7억수)*평채(1.5kg(x명체이탈율(5) x평체이탈율손실단가(1%당-3원) = 168억원/연간</td><td>168</td></tr><tr><td>계열화회사영 업손실</td><td>계열화회사의 사육손실의3배 추정 : 168x3=504억원/연간</td><td>504</td></tr><tr><td>산 란 계</td><td>농장</td><td>전국농장(A45호)*평균사육무수(7만수)*체중조절실매물(20 %)x21일간x계란값(60g-100원) = 277.8억원/연간</td><td>277.8</td></tr><tr><td colspan=\"3\">합계</td><td>1,115.4</td></tr></table> <p id='2' data-category='paragraph' style='font-size:16px'>자료: (주)하림 육계사육지원팀, 2020년도<br>출처: 2019년도 3/4분기 시도/사육규모별 가구수 및 마리수, 축산물품질평가원</p> <p id='3' data-category='paragraph' style='font-size:20px'>농장과 계열사 회사의 연평균 사육 손실금액은 육계와 산란계의 운영 과정에서 발생하<br>는 다양한 손실 요인으로 인해 연간 약 1,115.4억 원에 이르는 것으로 나타났다. 먼저 육<br>계와 관련된 손실을 살펴보면, 농장에서는 사료 단가와 평균 사육두수, 회전율, 사료전환<br>율(FCR)을 고려했을 때 연간 약 165.6억 원의 손실이 발생하는 것으로 분석되었다. 이는<br>사료 구매와 사육 관리 과정에서 발생하는 비용적 손실을 의미하며, 농가 운영의 효율성<br>을 높이기 위한 개선 방안이 필요함을 시사한다.</p> <br><p id='4' data-category='paragraph' style='font-size:20px'>한편, 계열화 회사의 사육실에서 발생하는 손실은 연간 약 168억 원으로 도계 과정에<br>서의 중량 손실과 평균 이탈율이 주요 요인으로 작용했다. 특히, 계열화 회사의 영업 손<br>실은 사육 손실의 3배인 약 504억 원으로 추정되며, 이는 전체 손실 금액의 약 45%를 차</p>' metadata={'page': 11}\n",
      "page_content='<p id='6' data-category='paragraph' style='font-size:20px'>지한다. 계열화 회사에서의 손실 비중이 큰 만큼, 영업 단계에서의 체계적 관리와 운영<br>개선이 중요한 과제로 부각된다.</p> <br><p id='7' data-category='paragraph' style='font-size:20px'>산란계 농장에서는 중량 조절 실패로 인해 연간 약 277.8억 원의 손실이 발생하는 것<br>으로 나타났다. 이는 산란계의 중량 조절 실패율과 계란 생산 기간, 계란 단가가 주요 변<br>수로 작용하며, 생산 효율성의 저하를 초래하는 요인으로 작용한다. 이러한 손실은 사료<br>공급, 환경 관리, 사육 기술 개선 등을 통해 줄일 수 있을 것으로 보인다.</p> <br><p id='8' data-category='paragraph' style='font-size:20px'>결과적으로, 육계 농장과 계열화 회사, 산란계 농장에서 발생하는 총 손실 금액은 연간<br>1,115.4억 원으로 분석되었다. 이는 농장 운영과 생산성 관리의 비효율성을 개선하고, 계<br>열화 회사의 사육 및 영업 프로세스를 최적화함으로써 큰 폭으로 감소될 가능성이 있다.<br>특히, 중량 예측 및 관리 시스템 도입, 최적 사육 환경 조성, 제중조절 실패율 감소를 위<br>한 기술적 지원이 필요하며, 이를 통해 농가와 계열사 회사 모두의 경제적 손실을 줄이<br>고 이윤을 극대화할 수 있을 것으로 기대된다.</p> <h1 id='9' style='font-size:20px'>1.2 연구 목적 및 방법</h1> <br><p id='10' data-category='paragraph' style='font-size:20px'>본 연구는 육계 농장에서 닭의 중량을 정확히 추정할 수 있는 데이터 분석 모델을 탐<br>구하고, 이를 활용한 시스템 개발 가능성을 제안하는 것을 목표로 한다. 이를 위해 다음<br>과 같은 단계로 연구를 진행한다.</p> <h1 id='11' style='font-size:20px'>1.2.1 데이터 수집 및 전처리</h1> <br><p id='12' data-category='paragraph' style='font-size:20px'>실제 육계 농장에서 사용하는 저울을 통해 다양한 시점의 중량 데이터를 수집한다. 수<br>집된 데이터는 일반적으로 복잡하고 누락된 값이 존재할 가능성이 높기 때문에, 데이터<br>병합 및 재구조화 과정을 통해 분석에 적합한 형태로 전처리한다.</p> <h1 id='13' style='font-size:16px'>1.2.2 모델 적용 및 비교</h1> <br><p id='14' data-category='paragraph' style='font-size:20px'>닭의 중량 데이터를 분석하기 위해 다양한 머신러닝 및 통계적 추정 모델을 적용한다.</p>' metadata={'page': 12}\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "\n",
    "file_path = '/content/data/유상민_육계중량추정을 위한 모델 비교.pdf'\n",
    "\n",
    "loader = UpstageLayoutAnalysisLoader(\n",
    "    file_path,\n",
    "    output_type = 'html',\n",
    "    split = 'page',\n",
    "    use_ocr = True,\n",
    "    exclude = [\"header\", 'footer'],\n",
    "    api_key= UPSTAGE_API_KEY\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "for doc in docs[8:11]:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3dfAwBapox2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZNISeSpIApO06GEJjcmFP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
