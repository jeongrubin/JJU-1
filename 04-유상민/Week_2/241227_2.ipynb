{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKKkBu6JmsZRaoUAp48zgb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"FPrzZElPwUrR","executionInfo":{"status":"ok","timestamp":1735281094002,"user_tz":-540,"elapsed":365,"user":{"displayName":"유상민","userId":"13412534722180768201"}}},"outputs":[],"source":["with open ('/content/appendix-keywords.txt') as f:\n","  file = f.read()"]},{"cell_type":"code","source":["print(file[:500])"],"metadata":{"id":"17S8EXswxjqT","executionInfo":{"status":"ok","timestamp":1735281094289,"user_tz":-540,"elapsed":9,"user":{"displayName":"유상민","userId":"13412534722180768201"}},"outputId":"b8405268-d01f-40f7-fea8-964572ccd30a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Semantic Search\n","\n","정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n","예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n","연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n","\n","Embedding\n","\n","정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n","예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n","연관키워드: 자연어 처리, 벡터화, 딥러닝\n","\n","Token\n","\n","정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n","예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n","연관키워드: 토큰화, 자연어\n"]}]},{"cell_type":"code","source":["from langchain_text_splitters import CharacterTextSplitter\n","\n","# CharacterTextSplitter를 사용하여 텍스트를 청크(chunk)로 분할하는 코드\n","text_splitter1 = CharacterTextSplitter(\n","    # 텍스트를 분할할 때 사용할 구분자를 지정합니다. 기본값은 \"\\n\\n\"입니다\n","    separator = '\\n\\n',\n","    # 분할된 텍스트 청크의 최대 크기를 지정합니다 (문자 수)\n","    chunk_size=150,\n","    # 분할된 텍스트 청크 간의 중복되는 문자 수를 지정합니다\n","    chunk_overlap=0,\n","    # 텍스트의 길이를 계산하는 함수를 지정합니다\n","    length_function=len,\n",")"],"metadata":{"id":"_L_rp3Um5_E8","executionInfo":{"status":"ok","timestamp":1735282763772,"user_tz":-540,"elapsed":382,"user":{"displayName":"유상민","userId":"13412534722180768201"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["texts = text_splitter1.create_documents([file])\n","print(len(texts[0].page_content))\n","print(texts[0])\n","print(\"===\" * 20)\n","print(texts[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NE-z-va6Aev","executionInfo":{"status":"ok","timestamp":1735282764085,"user_tz":-540,"elapsed":7,"user":{"displayName":"유상민","userId":"13412534722180768201"}},"outputId":"4dee724d-d983-4b90-f433-d1b00bcc1d47"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_text_splitters.base:Created a chunk of size 169, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 162, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 170, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 201, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 202, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 181, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 175, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 203, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 177, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 167, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 201, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 176, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 157, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 162, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 175, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 171, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 154, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 158, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 166, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 193, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 174, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 184, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 205, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 166, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 177, which is longer than the specified 150\n","WARNING:langchain_text_splitters.base:Created a chunk of size 157, which is longer than the specified 150\n"]},{"output_type":"stream","name":"stdout","text":["15\n","page_content='Semantic Search'\n","============================================================\n","page_content='정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n","예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n","연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝'\n"]}]},{"cell_type":"code","source":["from langchain_text_splitters import RecursiveCharacterTextSplitter"],"metadata":{"id":"tpWJf4wcw3I1","executionInfo":{"status":"ok","timestamp":1735282764086,"user_tz":-540,"elapsed":4,"user":{"displayName":"유상민","userId":"13412534722180768201"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["text_splitter2 = RecursiveCharacterTextSplitter(\n","    # 청크 크기를 매우 작게 설정.\n","    chunk_size = 300,\n","    # 정크 간의 중복되는 문자 수 설정\n","    chunk_overlap = 00,\n","    # 문자열 길이를 계산하는 함수 지정\n","    length_function = len,\n","    # 구분자로 정규식을 사용할지 여부를 설정\n","    # is_separater_regex  = False\n",")"],"metadata":{"id":"lmHsQ759zodd","executionInfo":{"status":"ok","timestamp":1735283146492,"user_tz":-540,"elapsed":354,"user":{"displayName":"유상민","userId":"13412534722180768201"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["texts = text_splitter2.create_documents([file])\n","print(texts[0])\n","print(\"===\" * 20)\n","print(texts[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElLVhdPm1F_d","executionInfo":{"status":"ok","timestamp":1735283148518,"user_tz":-540,"elapsed":308,"user":{"displayName":"유상민","userId":"13412534722180768201"}},"outputId":"1680eb60-a29c-4225-c0cb-579b02ba2193"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["page_content='Semantic Search\n","\n","정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n","예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n","연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n","\n","Embedding'\n","============================================================\n","page_content='정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n","예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n","연관키워드: 자연어 처리, 벡터화, 딥러닝\n","\n","Token'\n"]}]}]}