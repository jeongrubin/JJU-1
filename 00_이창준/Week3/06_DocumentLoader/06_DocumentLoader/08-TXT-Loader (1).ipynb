{"cells":[{"cell_type":"markdown","metadata":{"id":"9riiMTINhrhm"},"source":["# TXT Loader\n","\n","`.txt` 확장자를 가지는 파일을 로더로 로드하는 방법을 살펴보겠습니다."]},{"cell_type":"code","source":["!pip install -qU langchain_community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwmcqtsDh7Pm","executionInfo":{"status":"ok","timestamp":1735712579931,"user_tz":-540,"elapsed":11396,"user":{"displayName":"Chang Jun Lee","userId":"07449846774346066151"}},"outputId":"504079f3-35ec-44f0-d788-01adc7289ec8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCG-rRW9hrhn","executionInfo":{"status":"ok","timestamp":1735712601547,"user_tz":-540,"elapsed":1924,"user":{"displayName":"Chang Jun Lee","userId":"07449846774346066151"}},"outputId":"6b016239-a608-4005-b1ba-44a087e20480"},"outputs":[{"output_type":"stream","name":"stdout","text":["문서의 수: 1\n","\n","[메타데이터]\n","\n","{'source': '/content/appendix-keywords-utf8.txt'}\n","\n","========= [앞부분] 미리보기 =========\n","\n","Semantic Search\n","\n","정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n","예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n","연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n","\n","Embedding\n","\n","정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n","예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n","연관키워드: 자연어 처리, 벡터화, 딥러닝\n","\n","Token\n","\n","정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n","예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n","연관키워드: 토큰화, 자연어\n"]}],"source":["from langchain_community.document_loaders import TextLoader\n","\n","# 텍스트 로더 생성\n","loader = TextLoader(\"/content/appendix-keywords-utf8.txt\")\n","\n","# 문서 로드\n","docs = loader.load()\n","print(f\"문서의 수: {len(docs)}\\n\")\n","print(\"[메타데이터]\\n\")\n","print(docs[0].metadata)\n","print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n","print(docs[0].page_content[:500])"]},{"cell_type":"markdown","metadata":{"id":"xHM5Q_Ybhrhp"},"source":["## TextLoader를 통한 파일 인코딩 자동 감지\n","\n","이 예제에서는 TextLoader 클래스를 사용하여 디렉토리에서 임의의 파일 목록을 대량으로 로드할 때 유용한 몇 가지 전략을 살펴보겠습니다.\n","\n","먼저 문제를 설명하기 위해 임의의 인코딩으로 여러 개의 텍스트를 로드해 보겠습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"3TXlCM4Bhrhp"},"source":["- `silent_errors`: 디렉토리로더에 silent_errors 매개변수를 전달하여 로드할 수 없는 파일을 건너뛰고 로드 프로세스를 계속할 수 있습니다.\n","- `autodetect_encoding`: 또한 로더 클래스에 자동 감지\\_인코딩을 전달하여 실패하기 전에 파일 인코딩을 자동으로 감지하도록 요청할 수도 있습니다.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_a_4E_johrhp","executionInfo":{"status":"ok","timestamp":1735712668921,"user_tz":-540,"elapsed":366,"user":{"displayName":"Chang Jun Lee","userId":"07449846774346066151"}}},"outputs":[],"source":["from langchain_community.document_loaders import DirectoryLoader\n","\n","path = \"/content/\"\n","\n","text_loader_kwargs = {\"autodetect_encoding\": True}\n","\n","loader = DirectoryLoader(\n","    path,\n","    glob=\"**/*.txt\",\n","    loader_cls=TextLoader,\n","    silent_errors=True,\n","    loader_kwargs=text_loader_kwargs,\n",")\n","docs = loader.load()"]},{"cell_type":"markdown","metadata":{"id":"bJ4MoCRPhrhq"},"source":["`data/appendix-keywords.txt` 파일과 파일명이 유사한 파생 파일들은 모두 인코딩 방식이 다른 파일들입니다.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8pf9e1phrhq","executionInfo":{"status":"ok","timestamp":1735713228612,"user_tz":-540,"elapsed":367,"user":{"displayName":"Chang Jun Lee","userId":"07449846774346066151"}},"outputId":"1bcd21a5-bf1c-4d59-dcd9-d7db7c48cdb5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/appendix-keywords-utf8.txt']"]},"metadata":{},"execution_count":5}],"source":["doc_sources = [doc.metadata[\"source\"] for doc in docs]\n","doc_sources"]},{"cell_type":"markdown","source":["## 왜 에러가 날까요?\n","- docs가 하나라 [0]밖에 안됨."],"metadata":{"id":"Nogdl5oDk5pk"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w20_SoBFhrhq","executionInfo":{"status":"ok","timestamp":1735713261132,"user_tz":-540,"elapsed":335,"user":{"displayName":"Chang Jun Lee","userId":"07449846774346066151"}},"outputId":"2e9785cd-f622-4b54-994a-d35d6c648999"},"outputs":[{"output_type":"stream","name":"stdout","text":["[메타데이터]\n","\n","{'source': '/content/appendix-keywords-utf8.txt'}\n","\n","========= [앞부분] 미리보기 =========\n","\n","Semantic Search\n","\n","정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n","예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n","연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n","\n","Embedding\n","\n","정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n","예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n","연관키워드: 자연어 처리, 벡터화, 딥러닝\n","\n","Token\n","\n","정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n","예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n","연관키워드: 토큰화, 자연어\n"]}],"source":["print(\"[메타데이터]\\n\")\n","print(docs[3].metadata)\n","print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n","print(docs[3].page_content[:500])"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hoYjDFgnhrhq","executionInfo":{"status":"ok","timestamp":1735713287234,"user_tz":-540,"elapsed":310,"user":{"displayName":"Chang Jun Lee","userId":"07449846774346066151"}},"outputId":"bb447a80-1f6f-47e2-b54a-1e5bfa02402a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[메타데이터]\n","\n","{'source': '/content/appendix-keywords-utf8.txt'}\n","\n","========= [앞부분] 미리보기 =========\n","\n","Semantic Search\n","\n","정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n","예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n","연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n","\n","Embedding\n","\n","정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n","예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n","연관키워드: 자연어 처리, 벡터화, 딥러닝\n","\n","Token\n","\n","정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n","예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n","연관키워드: 토큰화, 자연어\n"]}],"source":["print(\"[메타데이터]\\n\")\n","print(docs[0].metadata)\n","print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n","print(docs[0].page_content[:500])"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7IAfN4Qhrhq","executionInfo":{"status":"ok","timestamp":1735713300895,"user_tz":-540,"elapsed":393,"user":{"displayName":"Chang Jun Lee","userId":"07449846774346066151"}},"outputId":"d0fdbb6f-20c1-4bc8-c51a-adde44a165b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[메타데이터]\n","\n","{'source': '/content/appendix-keywords-utf8.txt'}\n","\n","========= [앞부분] 미리보기 =========\n","\n","Semantic Search\n","\n","정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n","예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n","연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n","\n","Embedding\n","\n","정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n","예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n","연관키워드: 자연어 처리, 벡터화, 딥러닝\n","\n","Token\n","\n","정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n","예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n","연관키워드: 토큰화, 자연어\n"]}],"source":["print(\"[메타데이터]\\n\")\n","print(docs[0].metadata)\n","print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n","print(docs[0].page_content[:500])"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}